<!-- @format -->

# Modular AI Agent System

A Pythonic, GPU-accelerated, local-first AI research agent framework.

## Project Overview

This system provides a modular framework for AI agents that can perform various tasks, including research, code generation, and data analysis. It is designed to be:

- **Local-first**: Run models locally with GPU acceleration
- **Modular**: Easily add new agents and capabilities
- **Extensible**: Integrate with external services and APIs
- **Collaborative**: Agents can work together to solve complex problems

## Architecture

The system consists of two main components:

1. **Frontend**: Vite + React + TypeScript + TailwindCSS
2. **Backend**: FastAPI + Pydantic + Prefect + LLM integrations

## Getting Started

### Prerequisites

- Node.js 16+ and npm/yarn for frontend
- Python 3.11+ for backend
- Vulkan-compatible GPU for LLM acceleration

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/ai-agent-framework.git
cd ai-agent-framework

# Install frontend dependencies
cd frontend
npm install
cd ..

# Install backend dependencies
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
cd ..
```

### Running in Development Mode

```bash
# Run both frontend and backend
./run-dev.sh
```

This will start:
- Frontend at http://localhost:5173/
- Backend at http://localhost:8000/

## Project Structure

```
/ai-agent-framework
â”œâ”€â”€ frontend/           # Vite + React frontend
â”œâ”€â”€ backend/            # FastAPI backend
â”‚   â”œâ”€â”€ agents/         # Agent implementations
â”‚   â”œâ”€â”€ api/            # API endpoints
â”‚   â”œâ”€â”€ llm/            # LLM interfaces
â”‚   â”œâ”€â”€ memory/         # Memory systems
â”‚   â”œâ”€â”€ orchestration/  # Prefect workflows
â”‚   â””â”€â”€ integrations/   # External service integrations
â””â”€â”€ infra/              # Deployment and infrastructure
```

## Current Status

The project is currently in the **stubout** phase, with basic frontend and backend stubs implemented. The next step is to implement the full functionality in the **fullycode** phase.

---

## ğŸš€ Overview

This framework is designed to:

- Run modular autonomous agents using `llama.cpp` inference
- Coordinate multi-agent workflows with Prefect
- Store and retrieve knowledge via ChromaDB (with cloud sync)
- Integrate seamlessly with tools like Slack, Notion, GitHub
- Support local and AWS G5 deployment with one Dockerfile

---

## ğŸ§  Key Features

- **Agent Reflection Loops** â€“ Agents self-improve based on past outputs
- **Vulkan-Accelerated LLMs** â€“ Powered by `unsloth/gemma-3-4b-it` or `mistral-7b`
- **Shared + Isolated Memory** â€“ ChromaDB memory partitions with S3 sync
- **FastAPI + Async Architecture** â€“ API endpoints for research, memory, and integrations
- **Pluggable Integrations** â€“ Slack, Notion, GitHub, Jira (modular)
- **Frontend Dashboard** â€“ Vite + React + Tailwind + shadcn/ui for live UI feedback

---

## ğŸ§± Tech Stack

| Layer         | Stack                                          |
| ------------- | ---------------------------------------------- |
| LLM Backend   | llama.cpp + Vulkan + quantized models          |
| Agents        | Python classes w/ reasoning, reflection, tools |
| Orchestration | Prefect 2.x                                    |
| API Layer     | FastAPI, Pydantic v2                           |
| Memory        | ChromaDB (local), S3 sync, Pinecone optional   |
| Frontend      | Vite + React + TailwindCSS + shadcn/ui         |
| Deployment    | Docker (local/cloud), Terraform (AWS G5)       |

---

## ğŸ“‚ Project Structure

```bash
/ai-agent-framework
â”œâ”€â”€ frontend/                # Live UI powered by Vite/React
â”œâ”€â”€ backend/                 # Python modules
â”‚   â”œâ”€â”€ api/                 # FastAPI endpoints
â”‚   â”œâ”€â”€ agents/              # Agent class definitions
â”‚   â”œâ”€â”€ llm/                 # Inference wrappers (llama.cpp)
â”‚   â”œâ”€â”€ memory/              # ChromaDB abstraction
â”‚   â”œâ”€â”€ orchestration/       # Prefect flows
â”‚   â”œâ”€â”€ integrations/        # Slack, Notion, etc.
â”‚   â””â”€â”€ main.py              # FastAPI entrypoint
â”œâ”€â”€ infra/                   # Dockerfile + Terraform config
â”‚   â””â”€â”€ terraform/
â”œâ”€â”€ .cursorrules             # Project-wide Cursor rules
â”œâ”€â”€ README.md                # You are here
```

---

## ğŸ§ª Dev Workflow

1. **Phase 1**: [`masterplan.md`](./masterplan.md) â€“ Plan architecture and flows
2. **Phase 2**: [`stubout.md`](./stubout.md) â€“ Create stubbed files + live frontend
3. **Phase 3**: [`fullycode.md`](./fullycode.md) â€“ Build production-ready system

> ğŸ“Œ Frontend must always run before implementing backend logic

---

## ğŸ›  Setup Instructions

```bash
# Clone repo and enter project
$ git clone https://github.com/your-org/ai-agent-framework
$ cd ai-agent-framework

# Start frontend
$ cd frontend && npm install && npm run dev

# In new terminal, setup Python backend
$ cd backend && python3 -m venv venv && source venv/bin/activate
$ pip install -r requirements.txt
$ uvicorn main:app --reload
```

---

## ğŸ“¡ API Endpoints (WIP)

- `POST /research` â€“ Start research workflow
- `GET /memory/{agent_id}` â€“ Fetch memory snapshots
- `POST /integrations/{tool}` â€“ Trigger integration handlers

---

## ğŸ“‹ Todo / Status

- [x] Define architecture
- [x] Create dev rules + Cursor-compatible .mdc files
- [ ] Stub frontend + backend
- [ ] Build and test agent logic
- [ ] Integration modules (Slack, Notion, etc.)
- [ ] Prefect flows for reasoning and orchestration

---

## ğŸ” License

MIT Â© 2025 â€” Built for open collaboration
